{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- about\n",
    "# this file starts with notebook 'bootstrap' and does the following:\n",
    "# - download bootstrap results to a file\n",
    "# - compute confidence interval on development set accuracy\n",
    "# - compute test accuracy on test set\n",
    "\n",
    "# notebooks left to do:\n",
    "\n",
    "# add qa step to test bootstrap on normal distribution alongside spectra data\n",
    "# testing algorithms on pure spectra only, no mixtures\n",
    "# kfold\n",
    "# do multiple runs and record mean and variance of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- set up environment\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.artist as art\n",
    "from sklearn.decomposition import FastICA\n",
    "import bootstrapped.bootstrap as bs\n",
    "\n",
    "# for Set working folder, etc.\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# for sampling \n",
    "import random\n",
    "\n",
    "# test code\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- etl spectrum files\n",
    "\n",
    "# turn files into lists and cut off first line\n",
    "# put into database \"spectra\"\n",
    "# turn deleted points (flagged as -1.23e+34) into 0's\n",
    "# label spectra with datafile titles\n",
    "\n",
    "\n",
    "# - init spectra and class databases\n",
    "datafolder = \"C:/Users/Bonita/Documents/GitHub/spectra-ml/data/dataset3\"\n",
    "num_samples = len([name for name in os.listdir(datafolder) if \\\n",
    "                   os.path.isfile(os.path.join(datafolder,name))])\n",
    "# test code \n",
    "# print(num_samples)\n",
    "\n",
    "spectrum_len = 480                                 # 480 >= the BECK spectrometer spectrum length\n",
    "spectra = np.zeros((num_samples,spectrum_len))\n",
    "spectrum_categories = np.zeros(num_samples)\n",
    "first_record_of_mixtures_chapter = 11602\n",
    "is_a_mineral = 1                                   # these numbers match the chapter numbers given by usgs\n",
    "is_a_mixture = 2\n",
    "spectrum_names = [\"\" for x in range(num_samples)]\n",
    "\n",
    "y = np.zeros((num_samples, 1))\n",
    "\n",
    "\n",
    "# - fill databases\n",
    "i = 0\n",
    "\n",
    "# find spectra folder\n",
    "os.chdir(datafolder)\n",
    "\n",
    "# - etl the data\n",
    "# - create a spectrum_names string matrix for populating the plot legends\n",
    "# - find record number for identifying mixtures, which will be plotted in thicker lines\n",
    "for filename in os.listdir(datafolder):\n",
    "    \n",
    "    # read file\n",
    "    file_object  = open(filename, 'r').readlines()\n",
    "    # strip off header, add to matrix 'spectra'\n",
    "    spectra[i,:] = file_object[1:]                  \n",
    "    \n",
    "    # find file header\n",
    "    file_header = file_object[0]             \n",
    "                                        \n",
    "    # make spectrum_names matrix to label spectra in the plot legends\n",
    "    spectrum_names[i] = file_header\n",
    "    \n",
    "    # categorize spectrum as mineral or mixture:\n",
    "    # find record number in the header \n",
    "    # change from string to integer\n",
    "    # use it to identify and label minerals versus mixtures\n",
    "    # (minerals are records <=first_record_of_mixtures_chapter)\n",
    "    # (see report pg 3 from https://pubs.er.usgs.gov/publication/ds1035 \n",
    "    # ...for list of categories, 'chapters')\n",
    "    # (*will need to update if we want to use and categorize spectra from other categories)\n",
    "    # store category in spectra_category\n",
    "    ####\n",
    "    start = 'Record='\n",
    "    end = ':'\n",
    "    record_number = int((file_header.split(start))[1].split(end)[0])\n",
    "    # print(record_number)\n",
    "    if record_number < first_record_of_mixtures_chapter:\n",
    "        spectrum_categories[i] = is_a_mineral\n",
    "    else:\n",
    "        spectrum_categories[i] = is_a_mixture\n",
    "        \n",
    "    # testcode\n",
    "    # print('record_number: ', record_number)\n",
    "    \n",
    "    # testcode\n",
    "    # print(spectrum_categories)\n",
    "    \n",
    "    # testcode\n",
    "    # print(file_header)\n",
    "    \n",
    "    # label spectrum class, based on header\n",
    "    # actinolite: 0, alunite: 1, chlorite: 2\n",
    "    if file_header.find('Actinolite',)!= -1: #if material name contains actinolite\n",
    "        y[i,0] = 0\n",
    "    elif file_header.find('Alun',)!= -1:\n",
    "        y[i,0] = 1\n",
    "    else:                                       #chlorite\n",
    "        y[i,0] = 2         \n",
    "               \n",
    "    # turn deleted points into 0\n",
    "    for j in range(spectrum_len):  \n",
    "        if spectra[i,j] <0:\n",
    "            spectra[i,j]=0                          \n",
    "    i+=1\n",
    "\n",
    "# test code\n",
    "# print(y[:])\n",
    "# print(spectra[0:2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# --- etl \n",
    "\n",
    "# divide up data randomly into train, dev and test populations\n",
    "\n",
    "# 60% training set, 20% validation set, 20% test set \n",
    "sample_indices = list(range(0, num_samples))\n",
    "random.shuffle(sample_indices)\n",
    "train_population_size = 3*(num_samples//5)\n",
    "dev_population_size = (num_samples//5)\n",
    "test_population_size= num_samples-dev_population_size - train_population_size\n",
    "train_population_indices = sample_indices[0:train_population_size]\n",
    "dev_population_indices = sample_indices[train_population_size: train_population_size+dev_population_size]\n",
    "test_population_indices= sample_indices[train_population_size+dev_population_size: num_samples]\n",
    "\n",
    "#testcode\n",
    "print(len(train_population_indices)==train_population_size)\n",
    "print(len(dev_population_indices)==dev_population_size)\n",
    "#print(test_population_indices)\n",
    "\n",
    "#testcode\n",
    "#print(type(np.setdiff1d(sample_indices,train_set_indices)))\n",
    "      \n",
    "#dev_set_indices = random.sample(np.setdiff1d(sample_indices,train_set_indices), dev_set_size) #sample remaining spectra\n",
    "\n",
    "    \n",
    "\n",
    "# test code\n",
    "# print(train_set_size)\n",
    "# print(dev_set_size)\n",
    "# print(test_set_size)\n",
    "\n",
    "# test code\n",
    "# print(train_set_indices)\n",
    "# print(test_set_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plot the classes\n",
    "\n",
    "# plot each class in a separate plot\n",
    "# plot spectra names in legend\n",
    "# plot minerals and mixtures w diff line widths\n",
    "\n",
    "# variables\n",
    "num0 = 0 #number of samples of class 0\n",
    "num1 = 0\n",
    "num2 = 0\n",
    "\n",
    "mineral_linewidth = 1         # linewidth = 1 is default\n",
    "mixture_linewidth = 3         \n",
    "\n",
    "# count the number of each class to make spectra0, spectra1, spectra2 databases\n",
    "for i in range(num_samples):\n",
    "    if y[i,0]== 0:\n",
    "        num0 += 1\n",
    "    elif y[i,0]== 1:\n",
    "        num1 += 1\n",
    "    elif y[i,0]== 2:\n",
    "        num2 += 1\n",
    "\n",
    "# make class-specific databases spectra0, ...1, ...2\n",
    "spectra0 = np.zeros((num0,spectrum_len)) \n",
    "spectra1 = np.zeros((num1,spectrum_len)) \n",
    "spectra2 = np.zeros((num2,spectrum_len)) \n",
    "\n",
    "labels0 = [\"\" for x in range(num0)]\n",
    "labels1 = [\"\" for x in range(num1)]\n",
    "labels2 = [\"\" for x in range(num2)]\n",
    "\n",
    "linewidth0 = np.zeros(num0)\n",
    "linewidth1 = np.zeros(num1)\n",
    "linewidth2 = np.zeros(num2)\n",
    "\n",
    "\n",
    "# make counters for each database to place spectra\n",
    "i0 = 0\n",
    "i1 = 0\n",
    "i2 = 0\n",
    "\n",
    "# set linewidth for the spectrum \n",
    "# populate class-specific databases spectra0, ...1, ...2\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    # set linewidth\n",
    "    #testcode\n",
    "    #print(spectrum_categories)\n",
    "    #print(spectrum_categories[i])\n",
    "    \n",
    "    if spectrum_categories[i] == is_a_mineral:\n",
    "        linewidth = mineral_linewidth\n",
    "        \n",
    "        #testcode\n",
    "        #print('min')\n",
    "    else: \n",
    "        linewidth = mixture_linewidth\n",
    "        \n",
    "        #testcode\n",
    "        #print('mix')\n",
    "    \n",
    "    # populate matrices for making each class plot\n",
    "    if y[i,0]== 0:\n",
    "        spectra0[i0,:] = spectra[i,:]\n",
    "        labels0[i0] = spectrum_names[i]\n",
    "        linewidth0[i0] = linewidth\n",
    "        i0 +=1\n",
    "    elif y[i,0]== 1:\n",
    "        spectra1[i1,:] = spectra[i,:]\n",
    "        labels1[i1] = spectrum_names[i]\n",
    "        linewidth1[i1] = linewidth\n",
    "        i1 +=1\n",
    "    else:\n",
    "        spectra2[i2,:] = spectra[i,:]\n",
    "        labels2[i2] = spectrum_names[i]\n",
    "        linewidth2[i2] = linewidth\n",
    "        i2 +=1\n",
    "\n",
    "# plot each class-specific database separately\n",
    "for i in range(i0):\n",
    "    plt.plot(range(1, spectrum_len+1), spectra0[i,:], label = labels0[i], linewidth = linewidth0[i])\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()\n",
    "\n",
    "for i in range(i1):\n",
    "    plt.plot(range(1, spectrum_len+1), spectra1[i,:], label = labels1[i], linewidth = linewidth1[i])\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()\n",
    "\n",
    "for i in range(i2):\n",
    "    plt.plot(range(1, spectrum_len+1), spectra2[i,:], label = labels2[i], linewidth = linewidth2[i])\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- bootstrap variables\n",
    "\n",
    "num_bootstrap_runs = 100\n",
    "\n",
    "train_set_size = train_population_size\n",
    "dev_set_size = dev_population_size\n",
    "test_set_size = test_population_size\n",
    "\n",
    "num_model_types = 1                                 #plain nn (this is here because originally two models, nn and ica)\n",
    "num_tests_per_model = 2                             #train and dev accuracy \n",
    "num_tests = num_model_types*num_tests_per_model\n",
    "num_metrics_per_test = 2                                  #accuracy mean and var\n",
    "\n",
    "bresults = np.zeros((num_tests, num_bootstrap_runs))\n",
    "\n",
    "itrainnn = 0        #index in bresults of the train nn results\n",
    "idevnn = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- bootstrap loop\n",
    "\n",
    "# -select bootstrap sets\n",
    "# -run algorithm\n",
    "# -repeat num_bootstrap_runs times\n",
    "# -collect mean and variance of nn train, nn dev, ica train, ica test accuracies and store in bstatsfor run in range(num_bootstrap_runs):\n",
    "\n",
    "for run in range(num_bootstrap_runs):\n",
    "    # --- bootstrap sample the populations to make sets\n",
    "    # make train, dev, and test sets from their respective populations\n",
    "\n",
    "    #  draw with replacement from the populations\n",
    "    train_set_indices = random.choices(train_population_indices, k=train_set_size)\n",
    "    dev_set_indices = random.choices(dev_population_indices, k=dev_set_size)\n",
    "    test_set_indices = random.choices(test_population_indices, k=test_set_size)\n",
    "\n",
    "    # make train and test sets\n",
    "    train_set = spectra[train_set_indices, :]\n",
    "    train_set_labels = y[train_set_indices, :]\n",
    "    dev_set = spectra[dev_set_indices, :]\n",
    "    dev_set_labels = y[dev_set_indices,:]\n",
    "    test_set = spectra[test_set_indices, :]\n",
    "    test_set_labels = y[test_set_indices, :]    \n",
    "    \n",
    "    num_epochs = 15\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(300, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # compile\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # train\n",
    "    History = model.fit(train_set, train_set_labels, epochs=num_epochs)\n",
    "\n",
    "    acc = History.history['acc']\n",
    "    bresults[itrainnn, run] = acc[num_epochs-1]   #record plain nn train results\n",
    "    \n",
    "    #testcode\n",
    "    #print(bruns)    # --- test plain nn on dev set\n",
    "\n",
    "    dev_loss, dev_acc = model.evaluate(dev_set, dev_set_labels)\n",
    "\n",
    "    bresults[idevnn,run] = dev_acc\n",
    "    \n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- bootstrap stats\n",
    "print(run)\n",
    "print(bresults)\n",
    "\n",
    "num_stats = 2           #mean and var\n",
    "bstats = np.zeros((num_stats, num_tests))\n",
    "imean = 0               #row index of means\n",
    "ivar = 1\n",
    "\n",
    "nonemptyresults = bresults[:,:run]\n",
    "\n",
    "for test in range(num_tests):\n",
    "    bstats[imean,test] = np.mean(nonemptyresults[test,:])    \n",
    "    bstats[ivar,test] = np.var(nonemptyresults[test,:])\n",
    "\n",
    "print(bstats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- calculate bootstrap confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- test model on test set\n",
    "# model will be trained on the train population\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
