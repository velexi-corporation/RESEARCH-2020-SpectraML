{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment set up\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "from scipy import stats as st\n",
    "\n",
    "# working folder\n",
    "# directory = \"/Users/Srikar/Desktop/Velexi/spectra-ml/data\"\n",
    "data_dir = os.environ['DATA_DIR']\n",
    "os.chdir(data_dir)\n",
    "stddata_path = os.path.join(data_dir,\"Srikar-Standardized\")\n",
    "\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/Srikar/Desktop/Velexi/spectra-ml/lab-notebook/smunukutla/data.csv\", sep=\",\")\n",
    "record_nums = data.iloc[0, :].tolist()\n",
    "spectrum_names = data.iloc[1, :].tolist()\n",
    "y = data.iloc[2, :].astype(int).tolist()\n",
    "y = np.reshape(y, (len(y), 1))\n",
    "num_samples = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_len = 500\n",
    "spectra = np.zeros((num_samples,spectrum_len))\n",
    "wavelengths = np.zeros((1,spectrum_len))\n",
    "\n",
    "# y = np.zeros((num_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(record_nums)):\n",
    "    data = pd.read_csv(os.path.join(stddata_path,\"{}.csv\".format(record_nums[i])))\n",
    "    if i == 0:\n",
    "        wavelengths[i,:] = data.iloc[:, 0].to_numpy()\n",
    "    spectra[i,:] = data.iloc[:, 1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrum_len = 480\n",
    "# spectra = np.zeros((num_samples,spectrum_len))\n",
    "\n",
    "# spectrum_categories = np.zeros(num_samples)\n",
    "# first_record_of_mixtures_chapter = 11602\n",
    "# is_a_mineral = 1                                   # these numbers match the chapter numbers given by usgs\n",
    "# is_a_mixture = 2\n",
    "# spectrum_names = [\"\" for x in range(num_samples)]\n",
    "\n",
    "# y = np.zeros((num_samples, 1))\n",
    "\n",
    "# os.chdir(dataset)\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for filename in os.listdir(dataset):\n",
    "#     file_object  = open(filename, 'r').readlines()\n",
    "# #     strip off header, add to matrix 'spectra'\n",
    "#     spectra[i,:] = file_object[1:]\n",
    "\n",
    "# #     label spectrum class, based on header\n",
    "# #     actinolite: 0, alunite: 1, chlorite: 2\n",
    "#     material_name = file_object[0]\n",
    "    \n",
    "#     spectrum_names[i] = material_name\n",
    "    \n",
    "#     start = 'Record='\n",
    "#     end = ':'\n",
    "#     record_number = int((material_name.split(start))[1].split(end)[0])\n",
    "#     # print(record_number)\n",
    "#     if record_number < first_record_of_mixtures_chapter:\n",
    "#         spectrum_categories[i] = is_a_mineral\n",
    "#     else:\n",
    "#         spectrum_categories[i] = is_a_mixture\n",
    "\n",
    "# #     print(material_name)\n",
    "\n",
    "#     if material_name.find('Actinolite',) != -1: # if material name contains actinolite\n",
    "#         y[i,0] = 0\n",
    "#     elif material_name.find('Alun',)!= -1:\n",
    "#         y[i,0] = 1\n",
    "#     else: # chlorite\n",
    "#         y[i,0] = 2\n",
    "\n",
    "# #     turn missing points into 0\n",
    "#     for j in range(spectrum_len):\n",
    "#         if spectra[i,j] < 0:\n",
    "#             spectra[i,j] = 0\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plot the classes\n",
    "\n",
    "# plot each class in a separate plot\n",
    "# plot spectra names in legend\n",
    "# plot minerals and mixtures w diff line widths\n",
    "\n",
    "# mineral_names = [\"Actinolite\", \"Alunite\", \"Chlorite\"]\n",
    "\n",
    "# # variables\n",
    "# num0 = 0 #number of samples of class 0\n",
    "# num1 = 0\n",
    "# num2 = 0\n",
    "\n",
    "# mineral_linewidth = 1         # linewidth = 1 is default\n",
    "# mixture_linewidth = 3         \n",
    "\n",
    "# # count the number of each class to make spectra0, spectra1, spectra2 databases\n",
    "# for i in range(num_samples):\n",
    "#     if y[i,0]== 0:\n",
    "#         num0 += 1\n",
    "#     elif y[i,0]== 1:\n",
    "#         num1 += 1\n",
    "#     elif y[i,0]== 2:\n",
    "#         num2 += 1\n",
    "\n",
    "# # make class-specific databases spectra0, ...1, ...2\n",
    "# spectra0 = np.zeros((num0,spectrum_len)) \n",
    "# spectra1 = np.zeros((num1,spectrum_len)) \n",
    "# spectra2 = np.zeros((num2,spectrum_len)) \n",
    "\n",
    "# labels0 = [\"\" for x in range(num0)]\n",
    "# labels1 = [\"\" for x in range(num1)]\n",
    "# labels2 = [\"\" for x in range(num2)]\n",
    "\n",
    "# linewidth0 = np.zeros(num0)\n",
    "# linewidth1 = np.zeros(num1)\n",
    "# linewidth2 = np.zeros(num2)\n",
    "\n",
    "\n",
    "# # make counters for each database to place spectra\n",
    "# i0 = 0\n",
    "# i1 = 0\n",
    "# i2 = 0\n",
    "\n",
    "# # set linewidth for the spectrum \n",
    "# # populate class-specific databases spectra0, ...1, ...2\n",
    "# for i in range(num_samples):\n",
    "    \n",
    "#     # set linewidth\n",
    "#     #testcode\n",
    "#     #print(spectrum_categories)\n",
    "#     #print(spectrum_categories[i])\n",
    "    \n",
    "# #     if spectrum_categories[i] == is_a_mineral:\n",
    "# #         linewidth = mineral_linewidth\n",
    "        \n",
    "# #         #testcode\n",
    "# #         #print('min')\n",
    "# #     else: \n",
    "# #         linewidth = mixture_linewidth\n",
    "#     linewidth = 2\n",
    "        \n",
    "#         #testcode\n",
    "#         #print('mix')\n",
    "    \n",
    "#     # populate matrices for making each class plot\n",
    "#     if y[i,0]== 0:\n",
    "#         spectra0[i0,:] = spectra[i,:]\n",
    "#         labels0[i0] = spectrum_names[i]\n",
    "#         linewidth0[i0] = linewidth\n",
    "#         i0 +=1\n",
    "#     elif y[i,0]== 1:\n",
    "#         spectra1[i1,:] = spectra[i,:]\n",
    "#         labels1[i1] = spectrum_names[i]\n",
    "#         linewidth1[i1] = linewidth\n",
    "#         i1 +=1\n",
    "#     else:\n",
    "#         spectra2[i2,:] = spectra[i,:]\n",
    "#         labels2[i2] = spectrum_names[i]\n",
    "#         linewidth2[i2] = linewidth\n",
    "#         i2 +=1\n",
    "\n",
    "# plot each class-specific database separately\n",
    "# for i in range(i0):\n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra0[i,:], label = labels0[i], linewidth = linewidth0[i]) # remove linewidth for all mixtures/minerals to be standard\n",
    "#     plt.plot(wavelengths[0,:], spectra0[i,:]) # remove linewidth for all mixtures/minerals to be standard\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.show()\n",
    "#     path = \"/Users/Srikar/Desktop/Velexi/spectra-ml/lab-notebook/smunukutla/plots/\" + mineral_names[0] + str(i) + \".png\"\n",
    "#     fig.savefig(path, format = \"PNG\")\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(i1):\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra1[i,:], label = labels1[i], linewidth = linewidth1[i])\n",
    "#     plt.plot(wavelengths[0,:], spectra1[i,:])\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(i2):\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra2[i,:], label = labels2[i], linewidth = linewidth2[i])\n",
    "#     plt.plot(wavelengths[0,:], spectra2[i,:])\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D CNN: [1.0, 0.9444444, 0.9444444, 1.0, 0.8888889, 0.9444444, 0.9444444, 1.0, 0.8888889, 1.0]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/Srikar/Desktop/Velexi/spectra-ml/lab-notebook/smunukutla\")\n",
    "fi = open(\"indices.txt\", \"r\")\n",
    "\n",
    "stats = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_set_indices = ast.literal_eval(fi.readline())\n",
    "    test_set_indices = ast.literal_eval(fi.readline())\n",
    "    dev_set_indices = ast.literal_eval(fi.readline())\n",
    "    \n",
    "    for j in train_set_indices:\n",
    "        j = int(j)\n",
    "    for k in test_set_indices:\n",
    "        k = int(k)\n",
    "    for m in dev_set_indices:\n",
    "        m = int(m)\n",
    "    \n",
    "    train_set = spectra[train_set_indices, :]\n",
    "    train_labels = y[train_set_indices, :]\n",
    "    dev_set = spectra[dev_set_indices, :]\n",
    "    dev_labels = y[dev_set_indices, :]\n",
    "    test_set = spectra[test_set_indices, :]\n",
    "    test_labels = y[test_set_indices, :]\n",
    "\n",
    "    train_labels = train_labels.flatten()\n",
    "    dev_labels = dev_labels.flatten()\n",
    "    test_labels = test_labels.flatten()\n",
    "\n",
    "    train_set = np.reshape(train_set, (train_set.shape[0], spectrum_len, 1))\n",
    "    dev_set = np.reshape(dev_set, (dev_set.shape[0], spectrum_len, 1))\n",
    "    test_set = np.reshape(test_set, (test_set.shape[0], spectrum_len, 1))\n",
    "\n",
    "    train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "    dev_labels = np.reshape(dev_labels, (dev_labels.shape[0], 1))\n",
    "    test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    dev_labels = to_categorical(dev_labels)\n",
    "    test_labels = to_categorical(test_labels)\n",
    "    \n",
    "    model = Sequential() # tf upgrading to 2.0, after that we need to specify the dtype/construct all layers at once\n",
    "    # model.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "    model.add(Conv1D(64, 25, activation='relu', input_shape=(train_set.shape[1], 1))) # optional: , dtype=tf.dtypes.float64\n",
    "    model.add(Conv1D(64, 25, activation='relu'))\n",
    "    model.add(MaxPooling1D(4)) # 108 by 64 so far\n",
    "    model.add(Conv1D(100, 25, activation='relu'))\n",
    "    model.add(Conv1D(100, 25, activation='relu'))\n",
    "    model.add(MaxPooling1D(4))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(GlobalAveragePooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    BATCH_SIZE = 12\n",
    "    EPOCHS = 50\n",
    "\n",
    "    model.fit(train_set, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0, validation_data=(dev_set, dev_labels))\n",
    "    \n",
    "    my_list = model.evaluate(test_set, test_labels, verbose=0)\n",
    "    \n",
    "    stats.append(my_list[1])\n",
    "\n",
    "print(\"1D CNN:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = np.reshape(train_set, (train_set.shape[0], spectrum_len, 1))\n",
    "# dev_set = np.reshape(dev_set, (dev_set.shape[0], spectrum_len, 1))\n",
    "# test_set = np.reshape(test_set, (test_set.shape[0], spectrum_len, 1))\n",
    "\n",
    "# train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "# dev_labels = np.reshape(dev_labels, (dev_labels.shape[0], 1))\n",
    "# test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# dev_labels = to_categorical(dev_labels)\n",
    "# test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random.seed()\n",
    "# model = Sequential()\n",
    "# # model.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "# model.add(Conv1D(64, 25, activation='relu', input_shape=(train_set.shape[1], 1)))\n",
    "# model.add(Conv1D(64, 25, activation='relu'))\n",
    "# model.add(MaxPooling1D(4)) # 108 by 64 so far\n",
    "# model.add(Conv1D(100, 25, activation='relu'))\n",
    "# model.add(Conv1D(100, 25, activation='relu'))\n",
    "# model.add(MaxPooling1D(4))\n",
    "# # model.add(Dropout(0.5))\n",
    "# # model.add(GlobalAveragePooling1D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# BATCH_SIZE = 12\n",
    "# EPOCHS = 50\n",
    "\n",
    "# print(train_labels.shape)\n",
    "# model.fit(train_set, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_data=(dev_set, dev_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(test_set)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D CNN Results: DescribeResult(nobs=10, minmax=(0.8888889, 1.0), mean=0.95555556, variance=0.0019204393, skewness=-0.3436215817928314, kurtosis=-1.1530622041123735)\n"
     ]
    }
   ],
   "source": [
    "print(\"1D CNN Results:\", st.describe(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
