{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment set up\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# working folder\n",
    "# directory = \"/Users/Srikar/Desktop/Velexi/spectra-ml/data\"\n",
    "directory = os.environ['DATA_DIR']\n",
    "os.chdir(directory)\n",
    "\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrum_id</th>\n",
       "      <th>value_type</th>\n",
       "      <th>material</th>\n",
       "      <th>spectrometer_purity_code</th>\n",
       "      <th>measurement_type</th>\n",
       "      <th>raw_data_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23077</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Rangeland C03-022 S12% G22%</td>\n",
       "      <td>ASDFRa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Rangeland_C03-022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22344</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Marsh SPAL92%...a CRMS322v78</td>\n",
       "      <td>ASDFRa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Marsh_SPAL92%...a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22136</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Tumbleweed ANP92-2C Dry</td>\n",
       "      <td>BECKa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Tumbleweed_ANP92-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24017</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Rangeland L02-069 S00% G99%</td>\n",
       "      <td>ASDFRa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Rangeland_L02-069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21060</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Douglas-Fir YNP-DF-1 forest</td>\n",
       "      <td>AVIRISb</td>\n",
       "      <td>RTGC</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Douglas-Fir_YNP-D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrum_id   value_type                      material  \\\n",
       "0        23077  reflectance   Rangeland C03-022 S12% G22%   \n",
       "1        22344  reflectance  Marsh SPAL92%...a CRMS322v78   \n",
       "2        22136  reflectance       Tumbleweed ANP92-2C Dry   \n",
       "3        24017  reflectance   Rangeland L02-069 S00% G99%   \n",
       "4        21060  reflectance   Douglas-Fir YNP-DF-1 forest   \n",
       "\n",
       "  spectrometer_purity_code measurement_type  \\\n",
       "0                   ASDFRa             AREF   \n",
       "1                   ASDFRa             AREF   \n",
       "2                    BECKa             AREF   \n",
       "3                   ASDFRa             AREF   \n",
       "4                  AVIRISb             RTGC   \n",
       "\n",
       "                                       raw_data_path  \n",
       "0  ChapterV_Vegetation/splib07a_Rangeland_C03-022...  \n",
       "1  ChapterV_Vegetation/splib07a_Marsh_SPAL92%...a...  \n",
       "2  ChapterV_Vegetation/splib07a_Tumbleweed_ANP92-...  \n",
       "3  ChapterV_Vegetation/splib07a_Rangeland_L02-069...  \n",
       "4  ChapterV_Vegetation/splib07a_Douglas-Fir_YNP-D...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stddata_path = os.path.join(directory,\"Srikar-Standardized\")\n",
    "metadata = pd.read_csv(os.path.join(stddata_path,\"spectra-metadata.csv\"), sep=\"|\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = metadata[metadata['value_type'] == \"reflectance\"]\n",
    "metadata = metadata[~metadata['spectrometer_purity_code'].str.contains(\"NIC4\")]\n",
    "metadata = metadata[metadata['raw_data_path'].str.contains(\"ChapterM\")]\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_record(string):\n",
    "#     ind = string.find(\"|\")\n",
    "#     return string[:ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = metadata.iloc[0]\n",
    "# type(data)\n",
    "\n",
    "# metadata[metadata[\"material\"].str.match(\"Chlor\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_nums = []\n",
    "y = []\n",
    "spectrum_names = []\n",
    "\n",
    "act = 0\n",
    "aln = 0\n",
    "chl = 0\n",
    "\n",
    "for i in range(metadata.shape[0]):\n",
    "    data = metadata.iloc[i, :]\n",
    "    if data[2].find(\"Actinolite\") != -1: # if material name contains actinolite\n",
    "        record_nums.append(data[0])\n",
    "        y.append(int(0))\n",
    "        spectrum_names.append(\"Actinolite\")\n",
    "        act += 1\n",
    "    elif data[2].find(\"Alun\") != -1:\n",
    "        record_nums.append(data[0])\n",
    "        y.append(int(1))\n",
    "        spectrum_names.append(\"Alunite\")\n",
    "        aln += 1\n",
    "    elif (data[2].find(\"Chlorit\") != -1 or data[2].find(\"Chlor.\") != -1 or data[2].find(\"Chlor+\") != -1 or data[2].find(\"Chl.\") != -1):\n",
    "        record_nums.append(data[0])\n",
    "        y.append(int(2))\n",
    "        spectrum_names.append(\"Chlorite\")\n",
    "        chl += 1\n",
    "\n",
    "y = np.reshape(y, (len(y), 1))\n",
    "num_samples = len(record_nums)\n",
    "# print(num_samples)\n",
    "# print(len(y))\n",
    "# print(type(y))\n",
    "# print(act)\n",
    "# print(aln)\n",
    "# print(chl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_len = 500\n",
    "spectra = np.zeros((num_samples,spectrum_len))\n",
    "wavelengths = np.zeros((1,spectrum_len))\n",
    "\n",
    "# y = np.zeros((num_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for num in actinolite:\n",
    "#     shutil.copy2(stddata_path+\"/{}.csv\".format(num), directory+\"/Std_Actinolite\")\n",
    "# for num in alunite:\n",
    "#     shutil.copy2(stddata_path+\"/{}.csv\".format(num), directory+\"/Std_Alunite\")\n",
    "# for num in chlorite:\n",
    "#     shutil.copy2(stddata_path+\"/{}.csv\".format(num), directory+\"/Std_Chlorite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_neg = 0\n",
    "# for i in range(num_samples):\n",
    "#     hasnegative = False\n",
    "#     data = pd.read_csv(os.path.join(stddata_path,\"{}.csv\".format(record_nums[i])))\n",
    "#     if i == 0:\n",
    "#         wavelengths[i,:] = data.iloc[:, 0].to_numpy()\n",
    "#     spectra[i,:] = data.iloc[:, 1].to_numpy()\n",
    "#     for j in range(spectrum_len):\n",
    "#         if spectra[i,j] < 0:\n",
    "#             hasnegative = True\n",
    "#             spectra[i,j] = 0\n",
    "#     if hasnegative:\n",
    "#         print(record_nums[i])\n",
    "#         num_neg += 1\n",
    "# print(num_neg)\n",
    "# wavelengths\n",
    "# print(record_nums[43])\n",
    "# print(spectra[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrum_len = 480\n",
    "# spectra = np.zeros((num_samples,spectrum_len))\n",
    "\n",
    "# spectrum_categories = np.zeros(num_samples)\n",
    "# first_record_of_mixtures_chapter = 11602\n",
    "# is_a_mineral = 1                                   # these numbers match the chapter numbers given by usgs\n",
    "# is_a_mixture = 2\n",
    "# spectrum_names = [\"\" for x in range(num_samples)]\n",
    "\n",
    "# y = np.zeros((num_samples, 1))\n",
    "\n",
    "# os.chdir(dataset)\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for filename in os.listdir(dataset):\n",
    "#     file_object  = open(filename, 'r').readlines()\n",
    "# #     strip off header, add to matrix 'spectra'\n",
    "#     spectra[i,:] = file_object[1:]\n",
    "\n",
    "# #     label spectrum class, based on header\n",
    "# #     actinolite: 0, alunite: 1, chlorite: 2\n",
    "#     material_name = file_object[0]\n",
    "    \n",
    "#     spectrum_names[i] = material_name\n",
    "    \n",
    "#     start = 'Record='\n",
    "#     end = ':'\n",
    "#     record_number = int((material_name.split(start))[1].split(end)[0])\n",
    "#     # print(record_number)\n",
    "#     if record_number < first_record_of_mixtures_chapter:\n",
    "#         spectrum_categories[i] = is_a_mineral\n",
    "#     else:\n",
    "#         spectrum_categories[i] = is_a_mixture\n",
    "\n",
    "# #     print(material_name)\n",
    "\n",
    "#     if material_name.find('Actinolite',) != -1: # if material name contains actinolite\n",
    "#         y[i,0] = 0\n",
    "#     elif material_name.find('Alun',)!= -1:\n",
    "#         y[i,0] = 1\n",
    "#     else: # chlorite\n",
    "#         y[i,0] = 2\n",
    "\n",
    "# #     turn missing points into 0\n",
    "#     for j in range(spectrum_len):\n",
    "#         if spectra[i,j] < 0:\n",
    "#             spectra[i,j] = 0\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plot the classes\n",
    "\n",
    "# plot each class in a separate plot\n",
    "# plot spectra names in legend\n",
    "# plot minerals and mixtures w diff line widths\n",
    "\n",
    "mineral_names = [\"Actinolite\", \"Alunite\", \"Chlorite\"]\n",
    "\n",
    "# variables\n",
    "num0 = 0 #number of samples of class 0\n",
    "num1 = 0\n",
    "num2 = 0\n",
    "\n",
    "mineral_linewidth = 1         # linewidth = 1 is default\n",
    "mixture_linewidth = 3         \n",
    "\n",
    "# count the number of each class to make spectra0, spectra1, spectra2 databases\n",
    "for i in range(num_samples):\n",
    "    if y[i,0]== 0:\n",
    "        num0 += 1\n",
    "    elif y[i,0]== 1:\n",
    "        num1 += 1\n",
    "    elif y[i,0]== 2:\n",
    "        num2 += 1\n",
    "\n",
    "# make class-specific databases spectra0, ...1, ...2\n",
    "spectra0 = np.zeros((num0,spectrum_len)) \n",
    "spectra1 = np.zeros((num1,spectrum_len)) \n",
    "spectra2 = np.zeros((num2,spectrum_len)) \n",
    "\n",
    "labels0 = [\"\" for x in range(num0)]\n",
    "labels1 = [\"\" for x in range(num1)]\n",
    "labels2 = [\"\" for x in range(num2)]\n",
    "\n",
    "linewidth0 = np.zeros(num0)\n",
    "linewidth1 = np.zeros(num1)\n",
    "linewidth2 = np.zeros(num2)\n",
    "\n",
    "\n",
    "# make counters for each database to place spectra\n",
    "i0 = 0\n",
    "i1 = 0\n",
    "i2 = 0\n",
    "\n",
    "# set linewidth for the spectrum \n",
    "# populate class-specific databases spectra0, ...1, ...2\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    # set linewidth\n",
    "    #testcode\n",
    "    #print(spectrum_categories)\n",
    "    #print(spectrum_categories[i])\n",
    "    \n",
    "#     if spectrum_categories[i] == is_a_mineral:\n",
    "#         linewidth = mineral_linewidth\n",
    "        \n",
    "#         #testcode\n",
    "#         #print('min')\n",
    "#     else: \n",
    "#         linewidth = mixture_linewidth\n",
    "    linewidth = 2\n",
    "        \n",
    "        #testcode\n",
    "        #print('mix')\n",
    "    \n",
    "    # populate matrices for making each class plot\n",
    "    if y[i,0]== 0:\n",
    "        spectra0[i0,:] = spectra[i,:]\n",
    "        labels0[i0] = spectrum_names[i]\n",
    "        linewidth0[i0] = linewidth\n",
    "        i0 +=1\n",
    "    elif y[i,0]== 1:\n",
    "        spectra1[i1,:] = spectra[i,:]\n",
    "        labels1[i1] = spectrum_names[i]\n",
    "        linewidth1[i1] = linewidth\n",
    "        i1 +=1\n",
    "    else:\n",
    "        spectra2[i2,:] = spectra[i,:]\n",
    "        labels2[i2] = spectrum_names[i]\n",
    "        linewidth2[i2] = linewidth\n",
    "        i2 +=1\n",
    "\n",
    "# plot each class-specific database separately\n",
    "# for i in range(i0):\n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra0[i,:], label = labels0[i], linewidth = linewidth0[i]) # remove linewidth for all mixtures/minerals to be standard\n",
    "#     plt.plot(wavelengths[0,:], spectra0[i,:]) # remove linewidth for all mixtures/minerals to be standard\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.show()\n",
    "#     path = \"/Users/Srikar/Desktop/Velexi/spectra-ml/lab-notebook/smunukutla/plots/\" + mineral_names[0] + str(i) + \".png\"\n",
    "#     fig.savefig(path, format = \"PNG\")\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(i1):\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra1[i,:], label = labels1[i], linewidth = linewidth1[i])\n",
    "#     plt.plot(wavelengths[0,:], spectra1[i,:])\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(i2):\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra2[i,:], label = labels2[i], linewidth = linewidth2[i])\n",
    "#     plt.plot(wavelengths[0,:], spectra2[i,:])\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/Srikar/Desktop/Velexi/spectra-ml/lab-notebook/smunukutla\")\n",
    "fi = open(\"indices.txt\", \"r\")\n",
    "\n",
    "for i in range(10):\n",
    "    train_set_indices = ast.literal_eval(fi.readline())\n",
    "    test_set_indices = ast.literal_eval(fi.readline())\n",
    "    dev_set_indices = ast.literal_eval(fi.readline())\n",
    "    \n",
    "    for j in train_set_indices:\n",
    "        j = int(j)\n",
    "    for j in test_set_indices:\n",
    "        j = int(j)\n",
    "    for j in dev_set_indices:\n",
    "        j = int(j)\n",
    "    \n",
    "    train_set = spectra[train_set_indices, :]\n",
    "    train_labels = y[train_set_indices, :]\n",
    "    dev_set = spectra[dev_set_indices, :]\n",
    "    dev_labels = y[dev_set_indices, :]\n",
    "    test_set = spectra[test_set_indices, :]\n",
    "    test_labels = y[test_set_indices, :]\n",
    "\n",
    "    train_labels = train_labels.flatten()\n",
    "    dev_labels = dev_labels.flatten()\n",
    "    test_labels = test_labels.flatten()\n",
    "    \n",
    "    train_set = np.reshape(train_set, (train_set.shape[0], spectrum_len, 1))\n",
    "    dev_set = np.reshape(dev_set, (dev_set.shape[0], spectrum_len, 1))\n",
    "    test_set = np.reshape(test_set, (test_set.shape[0], spectrum_len, 1))\n",
    "\n",
    "    train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "    dev_labels = np.reshape(dev_labels, (dev_labels.shape[0], 1))\n",
    "    test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    dev_labels = to_categorical(dev_labels)\n",
    "    test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_indices = list(range(0, num_samples))\n",
    "# print(num_samples)\n",
    "# random.shuffle(sample_indices) # stratified sklearn split\n",
    "# train_set_size = 3*(num_samples//5)\n",
    "# dev_set_size = (num_samples//5)\n",
    "# test_set_size= num_samples-dev_set_size - train_set_size\n",
    "# print(train_set_size)\n",
    "# print(test_set_size)\n",
    "# print(dev_set_size)\n",
    "# train_set_indices = sample_indices[:train_set_size]\n",
    "# dev_set_indices = sample_indices[train_set_size: train_set_size+dev_set_size]\n",
    "# test_set_indices= sample_indices[train_set_size+dev_set_size: num_samples]\n",
    "# print(train_set_indices)\n",
    "# print(test_set_indices)\n",
    "# print(dev_set_indices)\n",
    "\n",
    "# train_set = spectra[train_set_indices, :]\n",
    "# train_labels = y[train_set_indices, :]\n",
    "# dev_set = spectra[dev_set_indices, :]\n",
    "# dev_labels = y[dev_set_indices, :]\n",
    "# test_set = spectra[test_set_indices, :]\n",
    "# test_labels = y[test_set_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = train_labels.flatten()\n",
    "# dev_labels = dev_labels.flatten()\n",
    "# test_labels = test_labels.flatten()\n",
    "# type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_set)\n",
    "# len(train_set[17])\n",
    "# print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = np.reshape(train_set, (train_set.shape[0], spectrum_len, 1))\n",
    "# dev_set = np.reshape(dev_set, (dev_set.shape[0], spectrum_len, 1))\n",
    "# test_set = np.reshape(test_set, (test_set.shape[0], spectrum_len, 1))\n",
    "\n",
    "# train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "# dev_labels = np.reshape(dev_labels, (dev_labels.shape[0], 1))\n",
    "# test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# dev_labels = to_categorical(dev_labels)\n",
    "# test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_64 (Conv1D)           (None, 476, 64)           1664      \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 452, 64)           102464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 113, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 89, 100)           160100    \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 65, 100)           250100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 16, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 4803      \n",
      "=================================================================\n",
      "Total params: 519,131\n",
      "Trainable params: 519,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# random.seed()\n",
    "model = Sequential()\n",
    "# model.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "model.add(Conv1D(64, 25, activation='relu', input_shape=(train_set.shape[1], 1)))\n",
    "model.add(Conv1D(64, 25, activation='relu'))\n",
    "model.add(MaxPooling1D(4)) # 108 by 64 so far\n",
    "model.add(Conv1D(100, 25, activation='relu'))\n",
    "model.add(Conv1D(100, 25, activation='relu'))\n",
    "model.add(MaxPooling1D(4))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (8, 2) was passed for an output of shape (None, 3) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-c7720917a94d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Programs/Virtual Environments/spectra-ml-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    722\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Programs/Virtual Environments/spectra-ml-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2690\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2692\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Programs/Virtual Environments/spectra-ml-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    547\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    548\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (8, 2) was passed for an output of shape (None, 3) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "EPOCHS = 50\n",
    "\n",
    "print(train_labels.shape)\n",
    "model.fit(train_set, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_data=(dev_set, dev_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9932851e-02, 9.4871266e-06, 9.6005762e-01],\n",
       "       [4.4050080e-06, 9.9982929e-01, 1.6631726e-04],\n",
       "       [9.6577060e-01, 4.3231712e-06, 3.4225050e-02],\n",
       "       [4.7074784e-02, 1.6136686e-05, 9.5290905e-01],\n",
       "       [3.8776520e-01, 5.7989305e-01, 3.2341786e-02],\n",
       "       [9.4017249e-01, 6.0250013e-06, 5.9821468e-02],\n",
       "       [2.3700120e-02, 5.9255707e-04, 9.7570735e-01],\n",
       "       [4.0465359e-02, 1.1649705e-04, 9.5941812e-01]], dtype=float32)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_set)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "8/8 [==============================] - 0s 3ms/sample - loss: 0.4604 - acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46038818359375, 0.875]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
