{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment set up\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# working folder\n",
    "# directory = \"/Users/Srikar/Desktop/Velexi/spectra-ml/data\"\n",
    "directory = os.environ['DATA_DIR']\n",
    "os.chdir(directory)\n",
    "\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrum_id</th>\n",
       "      <th>value_type</th>\n",
       "      <th>material</th>\n",
       "      <th>spectrometer_purity_code</th>\n",
       "      <th>measurement_type</th>\n",
       "      <th>raw_data_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23077</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Rangeland C03-022 S12% G22%</td>\n",
       "      <td>ASDFRa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Rangeland_C03-022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22344</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Marsh SPAL92%...a CRMS322v78</td>\n",
       "      <td>ASDFRa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Marsh_SPAL92%...a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22136</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Tumbleweed ANP92-2C Dry</td>\n",
       "      <td>BECKa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Tumbleweed_ANP92-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24017</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Rangeland L02-069 S00% G99%</td>\n",
       "      <td>ASDFRa</td>\n",
       "      <td>AREF</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Rangeland_L02-069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21060</td>\n",
       "      <td>reflectance</td>\n",
       "      <td>Douglas-Fir YNP-DF-1 forest</td>\n",
       "      <td>AVIRISb</td>\n",
       "      <td>RTGC</td>\n",
       "      <td>ChapterV_Vegetation/splib07a_Douglas-Fir_YNP-D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrum_id   value_type                      material  \\\n",
       "0        23077  reflectance   Rangeland C03-022 S12% G22%   \n",
       "1        22344  reflectance  Marsh SPAL92%...a CRMS322v78   \n",
       "2        22136  reflectance       Tumbleweed ANP92-2C Dry   \n",
       "3        24017  reflectance   Rangeland L02-069 S00% G99%   \n",
       "4        21060  reflectance   Douglas-Fir YNP-DF-1 forest   \n",
       "\n",
       "  spectrometer_purity_code measurement_type  \\\n",
       "0                   ASDFRa             AREF   \n",
       "1                   ASDFRa             AREF   \n",
       "2                    BECKa             AREF   \n",
       "3                   ASDFRa             AREF   \n",
       "4                  AVIRISb             RTGC   \n",
       "\n",
       "                                       raw_data_path  \n",
       "0  ChapterV_Vegetation/splib07a_Rangeland_C03-022...  \n",
       "1  ChapterV_Vegetation/splib07a_Marsh_SPAL92%...a...  \n",
       "2  ChapterV_Vegetation/splib07a_Tumbleweed_ANP92-...  \n",
       "3  ChapterV_Vegetation/splib07a_Rangeland_L02-069...  \n",
       "4  ChapterV_Vegetation/splib07a_Douglas-Fir_YNP-D...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stddata_path = os.path.join(directory,\"Srikar-Standardized\")\n",
    "metadata = pd.read_csv(os.path.join(stddata_path,\"spectra-metadata.csv\"), sep=\"|\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = metadata[metadata['value_type'] == \"reflectance\"]\n",
    "metadata = metadata[~metadata['spectrometer_purity_code'].str.contains(\"NIC4\")]\n",
    "metadata = metadata[metadata['raw_data_path'].str.contains(\"ChapterM\")]\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_record(string):\n",
    "#     ind = string.find(\"|\")\n",
    "#     return string[:ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = metadata.iloc[0]\n",
    "# type(data)\n",
    "\n",
    "# metadata[metadata[\"material\"].str.match(\"Chlor\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_nums = []\n",
    "y = []\n",
    "spectrum_names = []\n",
    "\n",
    "act = 0\n",
    "aln = 0\n",
    "chl = 0\n",
    "\n",
    "for i in range(metadata.shape[0]):\n",
    "    data = metadata.iloc[i, :]\n",
    "    if data[2].find(\"Actinolite\") != -1: # if material name contains actinolite\n",
    "        record_nums.append(data[0])\n",
    "        y.append(int(0))\n",
    "        spectrum_names.append(\"Actinolite\")\n",
    "        act += 1\n",
    "    elif data[2].find(\"Alun\") != -1:\n",
    "        record_nums.append(data[0])\n",
    "        y.append(int(1))\n",
    "        spectrum_names.append(\"Alunite\")\n",
    "        aln += 1\n",
    "    elif (data[2].find(\"Chlorit\") != -1 or data[2].find(\"Chlor.\") != -1 or data[2].find(\"Chlor+\") != -1 or data[2].find(\"Chl.\") != -1):\n",
    "        record_nums.append(data[0])\n",
    "        y.append(int(2))\n",
    "        spectrum_names.append(\"Chlorite\")\n",
    "        chl += 1\n",
    "\n",
    "y = np.reshape(y, (len(y), 1))\n",
    "num_samples = len(record_nums)\n",
    "# print(num_samples)\n",
    "# print(len(y))\n",
    "# print(type(y))\n",
    "# print(act)\n",
    "# print(aln)\n",
    "# print(chl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_len = 500\n",
    "spectra = np.zeros((num_samples,spectrum_len))\n",
    "wavelengths = np.zeros((1,spectrum_len))\n",
    "\n",
    "# y = np.zeros((num_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for num in actinolite:\n",
    "#     shutil.copy2(stddata_path+\"/{}.csv\".format(num), directory+\"/Std_Actinolite\")\n",
    "# for num in alunite:\n",
    "#     shutil.copy2(stddata_path+\"/{}.csv\".format(num), directory+\"/Std_Alunite\")\n",
    "# for num in chlorite:\n",
    "#     shutil.copy2(stddata_path+\"/{}.csv\".format(num), directory+\"/Std_Chlorite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_neg = 0\n",
    "# for i in range(num_samples):\n",
    "#     hasnegative = False\n",
    "#     data = pd.read_csv(os.path.join(stddata_path,\"{}.csv\".format(record_nums[i])))\n",
    "#     if i == 0:\n",
    "#         wavelengths[i,:] = data.iloc[:, 0].to_numpy()\n",
    "#     spectra[i,:] = data.iloc[:, 1].to_numpy()\n",
    "#     for j in range(spectrum_len):\n",
    "#         if spectra[i,j] < 0:\n",
    "#             hasnegative = True\n",
    "#             spectra[i,j] = 0\n",
    "#     if hasnegative:\n",
    "#         print(record_nums[i])\n",
    "#         num_neg += 1\n",
    "# print(num_neg)\n",
    "# wavelengths\n",
    "# print(record_nums[43])\n",
    "# print(spectra[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrum_len = 480\n",
    "# spectra = np.zeros((num_samples,spectrum_len))\n",
    "\n",
    "# spectrum_categories = np.zeros(num_samples)\n",
    "# first_record_of_mixtures_chapter = 11602\n",
    "# is_a_mineral = 1                                   # these numbers match the chapter numbers given by usgs\n",
    "# is_a_mixture = 2\n",
    "# spectrum_names = [\"\" for x in range(num_samples)]\n",
    "\n",
    "# y = np.zeros((num_samples, 1))\n",
    "\n",
    "# os.chdir(dataset)\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for filename in os.listdir(dataset):\n",
    "#     file_object  = open(filename, 'r').readlines()\n",
    "# #     strip off header, add to matrix 'spectra'\n",
    "#     spectra[i,:] = file_object[1:]\n",
    "\n",
    "# #     label spectrum class, based on header\n",
    "# #     actinolite: 0, alunite: 1, chlorite: 2\n",
    "#     material_name = file_object[0]\n",
    "    \n",
    "#     spectrum_names[i] = material_name\n",
    "    \n",
    "#     start = 'Record='\n",
    "#     end = ':'\n",
    "#     record_number = int((material_name.split(start))[1].split(end)[0])\n",
    "#     # print(record_number)\n",
    "#     if record_number < first_record_of_mixtures_chapter:\n",
    "#         spectrum_categories[i] = is_a_mineral\n",
    "#     else:\n",
    "#         spectrum_categories[i] = is_a_mixture\n",
    "\n",
    "# #     print(material_name)\n",
    "\n",
    "#     if material_name.find('Actinolite',) != -1: # if material name contains actinolite\n",
    "#         y[i,0] = 0\n",
    "#     elif material_name.find('Alun',)!= -1:\n",
    "#         y[i,0] = 1\n",
    "#     else: # chlorite\n",
    "#         y[i,0] = 2\n",
    "\n",
    "# #     turn missing points into 0\n",
    "#     for j in range(spectrum_len):\n",
    "#         if spectra[i,j] < 0:\n",
    "#             spectra[i,j] = 0\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plot the classes\n",
    "\n",
    "# plot each class in a separate plot\n",
    "# plot spectra names in legend\n",
    "# plot minerals and mixtures w diff line widths\n",
    "\n",
    "mineral_names = [\"Actinolite\", \"Alunite\", \"Chlorite\"]\n",
    "\n",
    "# variables\n",
    "num0 = 0 #number of samples of class 0\n",
    "num1 = 0\n",
    "num2 = 0\n",
    "\n",
    "mineral_linewidth = 1         # linewidth = 1 is default\n",
    "mixture_linewidth = 3         \n",
    "\n",
    "# count the number of each class to make spectra0, spectra1, spectra2 databases\n",
    "for i in range(num_samples):\n",
    "    if y[i,0]== 0:\n",
    "        num0 += 1\n",
    "    elif y[i,0]== 1:\n",
    "        num1 += 1\n",
    "    elif y[i,0]== 2:\n",
    "        num2 += 1\n",
    "\n",
    "# make class-specific databases spectra0, ...1, ...2\n",
    "spectra0 = np.zeros((num0,spectrum_len)) \n",
    "spectra1 = np.zeros((num1,spectrum_len)) \n",
    "spectra2 = np.zeros((num2,spectrum_len)) \n",
    "\n",
    "labels0 = [\"\" for x in range(num0)]\n",
    "labels1 = [\"\" for x in range(num1)]\n",
    "labels2 = [\"\" for x in range(num2)]\n",
    "\n",
    "linewidth0 = np.zeros(num0)\n",
    "linewidth1 = np.zeros(num1)\n",
    "linewidth2 = np.zeros(num2)\n",
    "\n",
    "\n",
    "# make counters for each database to place spectra\n",
    "i0 = 0\n",
    "i1 = 0\n",
    "i2 = 0\n",
    "\n",
    "# set linewidth for the spectrum \n",
    "# populate class-specific databases spectra0, ...1, ...2\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    # set linewidth\n",
    "    #testcode\n",
    "    #print(spectrum_categories)\n",
    "    #print(spectrum_categories[i])\n",
    "    \n",
    "#     if spectrum_categories[i] == is_a_mineral:\n",
    "#         linewidth = mineral_linewidth\n",
    "        \n",
    "#         #testcode\n",
    "#         #print('min')\n",
    "#     else: \n",
    "#         linewidth = mixture_linewidth\n",
    "    linewidth = 2\n",
    "        \n",
    "        #testcode\n",
    "        #print('mix')\n",
    "    \n",
    "    # populate matrices for making each class plot\n",
    "    if y[i,0]== 0:\n",
    "        spectra0[i0,:] = spectra[i,:]\n",
    "        labels0[i0] = spectrum_names[i]\n",
    "        linewidth0[i0] = linewidth\n",
    "        i0 +=1\n",
    "    elif y[i,0]== 1:\n",
    "        spectra1[i1,:] = spectra[i,:]\n",
    "        labels1[i1] = spectrum_names[i]\n",
    "        linewidth1[i1] = linewidth\n",
    "        i1 +=1\n",
    "    else:\n",
    "        spectra2[i2,:] = spectra[i,:]\n",
    "        labels2[i2] = spectrum_names[i]\n",
    "        linewidth2[i2] = linewidth\n",
    "        i2 +=1\n",
    "\n",
    "# plot each class-specific database separately\n",
    "# for i in range(i0):\n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra0[i,:], label = labels0[i], linewidth = linewidth0[i]) # remove linewidth for all mixtures/minerals to be standard\n",
    "#     plt.plot(wavelengths[0,:], spectra0[i,:]) # remove linewidth for all mixtures/minerals to be standard\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.show()\n",
    "#     path = \"/Users/Srikar/Desktop/Velexi/spectra-ml/lab-notebook/smunukutla/plots/\" + mineral_names[0] + str(i) + \".png\"\n",
    "#     fig.savefig(path, format = \"PNG\")\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(i1):\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra1[i,:], label = labels1[i], linewidth = linewidth1[i])\n",
    "#     plt.plot(wavelengths[0,:], spectra1[i,:])\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(i2):\n",
    "#     plt.plot(range(1, spectrum_len+1), spectra2[i,:], label = labels2[i], linewidth = linewidth2[i])\n",
    "#     plt.plot(wavelengths[0,:], spectra2[i,:])\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"/Users/Srikar/Desktop/Velexi/spectra-ml/lab-notebook/smunukutla\")\n",
    "# fi = open(\"indices.txt\", \"r\")\n",
    "\n",
    "# for i in range(10):\n",
    "#     train_set_indices = ast.literal_eval(fi.readline())\n",
    "#     test_set_indices = ast.literal_eval(fi.readline())\n",
    "#     dev_set_indices = ast.literal_eval(fi.readline())\n",
    "    \n",
    "#     for j in train_set_indices:\n",
    "#         j = int(j)\n",
    "#     for j in test_set_indices:\n",
    "#         j = int(j)\n",
    "#     for j in dev_set_indices:\n",
    "#         j = int(j)\n",
    "\n",
    "train_set_indices = [11, 4, 38, 12, 20, 34, 36, 31, 14, 10, 15, 28, 9, 27, 16, 17, 19, 6, 33, 37, 25, 21, 35, 5]\n",
    "test_set_indices = [29, 32, 18, 2, 24, 8, 7, 13]\n",
    "dev_set_indices = [23, 26, 22, 39, 3, 1, 30, 0]\n",
    "\n",
    "train_set = spectra[train_set_indices, :]\n",
    "train_labels = y[train_set_indices, :]\n",
    "dev_set = spectra[dev_set_indices, :]\n",
    "dev_labels = y[dev_set_indices, :]\n",
    "test_set = spectra[test_set_indices, :]\n",
    "test_labels = y[test_set_indices, :]\n",
    "\n",
    "train_labels = train_labels.flatten()\n",
    "dev_labels = dev_labels.flatten()\n",
    "test_labels = test_labels.flatten()\n",
    "\n",
    "train_set = np.reshape(train_set, (train_set.shape[0], spectrum_len, 1))\n",
    "dev_set = np.reshape(dev_set, (dev_set.shape[0], spectrum_len, 1))\n",
    "test_set = np.reshape(test_set, (test_set.shape[0], spectrum_len, 1))\n",
    "\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "dev_labels = np.reshape(dev_labels, (dev_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "dev_labels = to_categorical(dev_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_indices = list(range(0, num_samples))\n",
    "# print(num_samples)\n",
    "# random.shuffle(sample_indices) # stratified sklearn split\n",
    "# train_set_size = 3*(num_samples//5)\n",
    "# dev_set_size = (num_samples//5)\n",
    "# test_set_size= num_samples-dev_set_size - train_set_size\n",
    "# print(train_set_size)\n",
    "# print(test_set_size)\n",
    "# print(dev_set_size)\n",
    "# train_set_indices = sample_indices[:train_set_size]\n",
    "# dev_set_indices = sample_indices[train_set_size: train_set_size+dev_set_size]\n",
    "# test_set_indices= sample_indices[train_set_size+dev_set_size: num_samples]\n",
    "# print(train_set_indices)\n",
    "# print(test_set_indices)\n",
    "# print(dev_set_indices)\n",
    "\n",
    "# train_set = spectra[train_set_indices, :]\n",
    "# train_labels = y[train_set_indices, :]\n",
    "# dev_set = spectra[dev_set_indices, :]\n",
    "# dev_labels = y[dev_set_indices, :]\n",
    "# test_set = spectra[test_set_indices, :]\n",
    "# test_labels = y[test_set_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = train_labels.flatten()\n",
    "# dev_labels = dev_labels.flatten()\n",
    "# test_labels = test_labels.flatten()\n",
    "# type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_set)\n",
    "# len(train_set[17])\n",
    "# print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = np.reshape(train_set, (train_set.shape[0], spectrum_len, 1))\n",
    "# dev_set = np.reshape(dev_set, (dev_set.shape[0], spectrum_len, 1))\n",
    "# test_set = np.reshape(test_set, (test_set.shape[0], spectrum_len, 1))\n",
    "\n",
    "# train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "# dev_labels = np.reshape(dev_labels, (dev_labels.shape[0], 1))\n",
    "# test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# dev_labels = to_categorical(dev_labels)\n",
    "# test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 476, 64)           1664      \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 452, 64)           102464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 113, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 89, 100)           160100    \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 65, 100)           250100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 16, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 4803      \n",
      "=================================================================\n",
      "Total params: 519,131\n",
      "Trainable params: 519,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# random.seed()\n",
    "model = Sequential()\n",
    "# model.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "model.add(Conv1D(64, 25, activation='relu', input_shape=(train_set.shape[1], 1)))\n",
    "model.add(Conv1D(64, 25, activation='relu'))\n",
    "model.add(MaxPooling1D(4)) # 108 by 64 so far\n",
    "model.add(Conv1D(100, 25, activation='relu'))\n",
    "model.add(Conv1D(100, 25, activation='relu'))\n",
    "model.add(MaxPooling1D(4))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 3)\n",
      "Train on 24 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 23ms/sample - loss: 1.0988 - acc: 0.2083 - val_loss: 1.0987 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0986 - acc: 0.4167 - val_loss: 1.0989 - val_acc: 0.2500\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0983 - acc: 0.4167 - val_loss: 1.0991 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 11ms/sample - loss: 1.0980 - acc: 0.4167 - val_loss: 1.0992 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 11ms/sample - loss: 1.0980 - acc: 0.4167 - val_loss: 1.0994 - val_acc: 0.2500\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0978 - acc: 0.4167 - val_loss: 1.0996 - val_acc: 0.2500\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 13ms/sample - loss: 1.0975 - acc: 0.4167 - val_loss: 1.0997 - val_acc: 0.2500\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 14ms/sample - loss: 1.0973 - acc: 0.4167 - val_loss: 1.0999 - val_acc: 0.2500\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0971 - acc: 0.4167 - val_loss: 1.1000 - val_acc: 0.2500\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0968 - acc: 0.4167 - val_loss: 1.1002 - val_acc: 0.2500\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 11ms/sample - loss: 1.0967 - acc: 0.4167 - val_loss: 1.1003 - val_acc: 0.2500\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0965 - acc: 0.4167 - val_loss: 1.1005 - val_acc: 0.2500\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0964 - acc: 0.4167 - val_loss: 1.1006 - val_acc: 0.2500\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0962 - acc: 0.4167 - val_loss: 1.1008 - val_acc: 0.2500\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/sample - loss: 1.0960 - acc: 0.4167 - val_loss: 1.1010 - val_acc: 0.2500\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0958 - acc: 0.4167 - val_loss: 1.1011 - val_acc: 0.2500\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0956 - acc: 0.4167 - val_loss: 1.1013 - val_acc: 0.2500\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0954 - acc: 0.4167 - val_loss: 1.1014 - val_acc: 0.2500\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 8ms/sample - loss: 1.0953 - acc: 0.4167 - val_loss: 1.1016 - val_acc: 0.2500\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0952 - acc: 0.4167 - val_loss: 1.1018 - val_acc: 0.2500\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0949 - acc: 0.4167 - val_loss: 1.1019 - val_acc: 0.2500\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0947 - acc: 0.4167 - val_loss: 1.1021 - val_acc: 0.2500\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0946 - acc: 0.4167 - val_loss: 1.1023 - val_acc: 0.2500\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0945 - acc: 0.4167 - val_loss: 1.1025 - val_acc: 0.2500\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 14ms/sample - loss: 1.0943 - acc: 0.4167 - val_loss: 1.1026 - val_acc: 0.2500\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 23ms/sample - loss: 1.0940 - acc: 0.4167 - val_loss: 1.1028 - val_acc: 0.2500\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 11ms/sample - loss: 1.0938 - acc: 0.4167 - val_loss: 1.1030 - val_acc: 0.2500\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0938 - acc: 0.4167 - val_loss: 1.1031 - val_acc: 0.2500\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 22ms/sample - loss: 1.0935 - acc: 0.4167 - val_loss: 1.1033 - val_acc: 0.2500\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 14ms/sample - loss: 1.0934 - acc: 0.4167 - val_loss: 1.1035 - val_acc: 0.2500\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 30ms/sample - loss: 1.0932 - acc: 0.4167 - val_loss: 1.1037 - val_acc: 0.2500\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 14ms/sample - loss: 1.0930 - acc: 0.4167 - val_loss: 1.1038 - val_acc: 0.2500\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0928 - acc: 0.4167 - val_loss: 1.1040 - val_acc: 0.2500\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 1.0928 - acc: 0.4167 - val_loss: 1.1042 - val_acc: 0.2500\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 20ms/sample - loss: 1.0925 - acc: 0.4167 - val_loss: 1.1043 - val_acc: 0.2500\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 15ms/sample - loss: 1.0923 - acc: 0.4167 - val_loss: 1.1045 - val_acc: 0.2500\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 15ms/sample - loss: 1.0923 - acc: 0.4167 - val_loss: 1.1047 - val_acc: 0.2500\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 18ms/sample - loss: 1.0920 - acc: 0.4167 - val_loss: 1.1048 - val_acc: 0.2500\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 11ms/sample - loss: 1.0920 - acc: 0.4167 - val_loss: 1.1050 - val_acc: 0.2500\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 27ms/sample - loss: 1.0918 - acc: 0.4167 - val_loss: 1.1052 - val_acc: 0.2500\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 20ms/sample - loss: 1.0916 - acc: 0.4167 - val_loss: 1.1054 - val_acc: 0.2500\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 10ms/sample - loss: 1.0914 - acc: 0.4167 - val_loss: 1.1055 - val_acc: 0.2500\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 11ms/sample - loss: 1.0913 - acc: 0.4167 - val_loss: 1.1057 - val_acc: 0.2500\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 17ms/sample - loss: 1.0911 - acc: 0.4167 - val_loss: 1.1058 - val_acc: 0.2500\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 14ms/sample - loss: 1.0910 - acc: 0.4167 - val_loss: 1.1060 - val_acc: 0.2500\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 15ms/sample - loss: 1.0909 - acc: 0.4167 - val_loss: 1.1062 - val_acc: 0.2500\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 18ms/sample - loss: 1.0908 - acc: 0.4167 - val_loss: 1.1064 - val_acc: 0.2500\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 22ms/sample - loss: 1.0906 - acc: 0.4167 - val_loss: 1.1066 - val_acc: 0.2500\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 26ms/sample - loss: 1.0905 - acc: 0.4167 - val_loss: 1.1067 - val_acc: 0.2500\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 17ms/sample - loss: 1.0903 - acc: 0.4167 - val_loss: 1.1069 - val_acc: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x132e444e0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "EPOCHS = 50\n",
    "\n",
    "print(train_labels.shape)\n",
    "model.fit(train_set, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_data=(dev_set, dev_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31296292, 0.33364105, 0.3533961 ],\n",
       "       [0.31296292, 0.33364105, 0.3533961 ],\n",
       "       [0.31296292, 0.33364105, 0.3533961 ],\n",
       "       [0.31296292, 0.33364105, 0.3533961 ],\n",
       "       [0.31296292, 0.33364105, 0.3533961 ],\n",
       "       [0.31296292, 0.33364105, 0.3533961 ],\n",
       "       [0.31296292, 0.33364105, 0.3533961 ],\n",
       "       [0.31296292, 0.33364105, 0.3533961 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_set)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (8, 2) was passed for an output of shape (None, 3) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-19caba999f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Programs/Virtual Environments/spectra-ml-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Programs/Virtual Environments/spectra-ml-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2690\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2692\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Programs/Virtual Environments/spectra-ml-env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    547\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    548\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (8, 2) was passed for an output of shape (None, 3) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "model.evaluate(test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
