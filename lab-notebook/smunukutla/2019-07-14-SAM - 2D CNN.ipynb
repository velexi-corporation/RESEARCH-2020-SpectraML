{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy import stats as st\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_len = 500 # automate this\n",
    "data_dir = os.environ['DATA_DIR']\n",
    "parent_dir = os.environ['PWD']\n",
    "stddata_path = os.path.join(data_dir, \"StdData-\" + str(spectrum_len))\n",
    "plots_dir = os.path.join(data_dir, \"plots-\" + str(spectrum_len))\n",
    "os.chdir(os.path.join(parent_dir, \"lab-notebook\", \"smunukutla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(os.path.join(plots_dir, os.listdir(plots_dir)[0]))\n",
    "spectrum_height = img.shape[0]\n",
    "spectrum_width = img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertimg(img):\n",
    "    newimg = np.empty([img.shape[0], img.shape[1]])\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            row = img[i][j]\n",
    "            newimg[i][j] = (row[0] + row[1] + row[2])/3\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\", sep=\",\")\n",
    "record_nums = data.iloc[0, :].tolist()\n",
    "spectrum_names = data.iloc[1, :].tolist()\n",
    "y = data.iloc[2, :].astype(int).tolist()\n",
    "y = np.reshape(y, (len(y), 1))\n",
    "num_samples = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.4461829662323\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "spectra = np.zeros((num_samples, spectrum_height, spectrum_width))\n",
    "i = 0\n",
    "for num in record_nums:\n",
    "    img = plt.imread(os.path.join(plots_dir, num + \"-\" + spectrum_names[i] + \".png\")) # look into timeit, pickle file\n",
    "    spectra[i] = convertimg(img)\n",
    "    i += 1\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 216, 324, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra = spectra.reshape(spectra.shape[0], spectra.shape[1], spectra.shape[2], 1)\n",
    "spectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D CNN Results: DescribeResult(nobs=20, minmax=(0.7058824, 0.9117647), mean=0.8, variance=0.003788016, skewness=0.2941734790802002, kurtosis=-0.7808808309173831)\n",
      "242.75860810279846\n"
     ]
    }
   ],
   "source": [
    "fi = open(\"indices.txt\", \"r\")\n",
    "num_runs = int(fi.readline())\n",
    "num_minerals = int(fi.readline())\n",
    "\n",
    "stats = []\n",
    "\n",
    "init_time = time.time()\n",
    "\n",
    "for i in range(num_runs):\n",
    "    train_set_indices = ast.literal_eval(fi.readline())\n",
    "    test_set_indices = ast.literal_eval(fi.readline())\n",
    "    dev_set_indices = ast.literal_eval(fi.readline())\n",
    "\n",
    "    for j in train_set_indices:\n",
    "        j = int(j)\n",
    "    for k in test_set_indices:\n",
    "        k = int(k)\n",
    "    for m in dev_set_indices:\n",
    "        m = int(m)\n",
    "        \n",
    "#     print(train_set_indices)\n",
    "#     print(test_set_indices)\n",
    "#     print(dev_set_indices)\n",
    "    \n",
    "    train_set = spectra[train_set_indices, :]\n",
    "#     train_labels = y[train_set_indices, :]\n",
    "    dev_set = spectra[dev_set_indices, :]\n",
    "#     dev_labels = y[dev_set_indices, :]\n",
    "    test_set = spectra[test_set_indices, :]\n",
    "#     test_labels = y[test_set_indices, :]\n",
    "\n",
    "#     train_labels = to_categorical(train_labels)\n",
    "#     dev_labels = to_categorical(dev_labels)\n",
    "#     test_labels = to_categorical(test_labels) # take apart the input and the output\n",
    "    \n",
    "    train_labels = y_cat[train_set_indices, :]\n",
    "    dev_labels = y_cat[dev_set_indices, :]\n",
    "    test_labels = y_cat[test_set_indices, :]\n",
    "    \n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(32, kernel_size=10, strides=(6,6), activation='relu', input_shape=(spectra.shape[1],spectra.shape[2], 1))) # finer features at the first layer\n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu')) # larger features at later layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_minerals, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 25\n",
    "    \n",
    "#     checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "#                                verbose=0,\n",
    "#                                save_best_only=True)\n",
    "#     tensorboard = TensorBoard(log_dir='./logs',\n",
    "#                           histogram_freq=0,\n",
    "#                           write_graph=True,\n",
    "#                           write_images=True)\n",
    "    \n",
    "#     history = model.fit(train_set, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0, validation_data=(dev_set, dev_labels), callbacks=[checkpointer, tensorboard]).history\n",
    "    model.fit(train_set, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0, validation_data=(dev_set, dev_labels))\n",
    "    \n",
    "    preds = model.evaluate(test_set, test_labels, verbose=0)\n",
    "    \n",
    "    stats.append(preds[1])\n",
    "\n",
    "print(\"2D CNN Results:\", st.describe(stats))\n",
    "total_seconds = time.time() - init_time\n",
    "print(total_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('2D CNN loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['acc'])\n",
    "plt.plot(history['val_acc'])\n",
    "plt.title('2D CNN accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('2dcnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
