{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for Set working folder, etc.\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# for sampling \n",
    "import random\n",
    "\n",
    "# set working folder\n",
    "# fw slashes for windows\n",
    "cwd_desired = \"C:/Users/Bonita/Documents/work/velexi/neural networks\" \n",
    "os.chdir(cwd_desired) \n",
    "\n",
    "# test code\n",
    "# print(os.getcwd())                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ETL spectrum files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# etl spectrum files\n",
    "\n",
    "# turn files into lists and cut off first line\n",
    "# put into database \"spectra\"\n",
    "# turn deleted points (flagged as -1.23e+34) into 0's\n",
    "\n",
    "\n",
    "# init spectra and class databases\n",
    "spectra_wd = str(cwd_desired + \"/spectra2\")\n",
    "num_samples = len([name for name in os.listdir(spectra_wd) if \\\n",
    "                   os.path.isfile(os.path.join(spectra_wd,name))])\n",
    "# test code \n",
    "print(num_samples)\n",
    "\n",
    "spectrum_len = 480                                 # 480 >= the BECK spectrometer spectrum length\n",
    "spectra = np.zeros((num_samples,spectrum_len))             \n",
    "y = np.zeros((num_samples, 1))\n",
    "\n",
    "# fill databases\n",
    "i = 0\n",
    "\n",
    "# find spectra folder\n",
    "os.chdir(spectra_wd)\n",
    "\n",
    "# etl the data\n",
    "for filename in os.listdir(spectra_wd):\n",
    "    file_object  = open(filename, 'r').readlines()\n",
    "    # strip off header, add to matrix 'spectra'\n",
    "    spectra[i,:] = file_object[1:]                  \n",
    "    \n",
    "    # label spectrum class, based on header\n",
    "    # actinolite: 0, alunite: 1\n",
    "    material_name = file_object[0]\n",
    "    \n",
    "    # testcode\n",
    "    # print(material_name)\n",
    "    \n",
    "    if material_name.find('Actinolite',)!= -1: #if material name contains actinolite\n",
    "        y[i,0] = 0\n",
    "    elif material_name.find('Alunite',)!= -1:\n",
    "        y[i,0] = 1\n",
    "    else:    \n",
    "        y[i,0] = 2\n",
    "               \n",
    "    # turn deleted points into 0\n",
    "    for j in range(spectrum_len):  \n",
    "        if spectra[i,j] <0:\n",
    "            spectra[i,j]=0                          \n",
    "    i+=1\n",
    "\n",
    "# test code\n",
    "# print(y[:])\n",
    "# print(spectra[0:2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide up data randomly\n",
    "\n",
    "# 80% training data 20% test for this pilot\n",
    "# eventually, 60% training set, 20% validation set, 20% test set\n",
    "samples = list(range(0, num_samples))\n",
    "train_set_size = 4*(num_samples//5)\n",
    "test_set_size= num_samples-train_set_size\n",
    "train_set_indices = random.sample(samples,train_set_size)\n",
    "test_set_indices = np.setdiff1d(samples,train_set_indices)     #fixed bug: take remaining samples after making train set\n",
    "\n",
    "# test code\n",
    "# print(train_set_indices)\n",
    "# print(test_set_indices)\n",
    "\n",
    "# make train and test sets\n",
    "\n",
    "train_set = spectra[train_set_indices, :]\n",
    "train_labels = y[train_set_indices, :]\n",
    "test_set = spectra[test_set_indices, :]\n",
    "test_labels = y[test_set_indices, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- make model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 1.0932 - acc: 0.4583\n",
      "Epoch 2/15\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9341 - acc: 0.5000\n",
      "Epoch 3/15\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9112 - acc: 0.5000\n",
      "Epoch 4/15\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9345 - acc: 0.5000\n",
      "Epoch 5/15\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9484 - acc: 0.5000\n",
      "Epoch 6/15\n",
      "24/24 [==============================] - 0s 209us/step - loss: 0.9475 - acc: 0.5000\n",
      "Epoch 7/15\n",
      "24/24 [==============================] - 0s 251us/step - loss: 0.9344 - acc: 0.5000\n",
      "Epoch 8/15\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9155 - acc: 0.5000\n",
      "Epoch 9/15\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.8972 - acc: 0.5000\n",
      "Epoch 10/15\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8859 - acc: 0.5000\n",
      "Epoch 11/15\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.8823 - acc: 0.5000\n",
      "Epoch 12/15\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8822 - acc: 0.5000\n",
      "Epoch 13/15\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.8823 - acc: 0.5000\n",
      "Epoch 14/15\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8798 - acc: 0.5000\n",
      "Epoch 15/15\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8736 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cf9d42c8d0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make model\n",
    "\n",
    "# build model\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit(train_set, train_labels, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 51ms/step\n",
      "Test accuracy: 0.375\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_set, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plot spectra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
